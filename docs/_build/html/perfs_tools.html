

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Performance evaluation tools &mdash; N2D2  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorials" href="tuto.html" />
    <link rel="prev" title="Performing simulations" href="simus.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> N2D2
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Presentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="about.html">About N2D2-IP</a></li>
<li class="toctree-l1"><a class="reference internal" href="simus.html">Performing simulations</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performance evaluation tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#key-performance-metrics">Key performance metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#interactive-confusion-matrix-tool">Interactive Confusion Matrix Tool</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#single-class-performances-evaluation">Single class performances evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#classes-aggregation">Classes aggregation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#selected-items-table-view">Selected items table view</a></li>
<li class="toctree-l3"><a class="reference internal" href="#items-viewer">Items viewer</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#automatic-performances-report-generation">Automatic Performances Report Generation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tuto.html">Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">ONNX Import:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="onnx_convert.html">Obtain ONNX models</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_import.html">Import ONNX models</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_transfer.html">Train from ONNX models</a></li>
</ul>
<p class="caption"><span class="caption-text">Quantization and Export:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quant_post.html">Post-training quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="quant_qat.html">Quantization aware training</a></li>
<li class="toctree-l1"><a class="reference internal" href="export_CPP.html">Export: C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="export_CPP_STM32.html">Export: C++/STM32</a></li>
<li class="toctree-l1"><a class="reference internal" href="export_TensorRT.html">Export: TensorRT</a></li>
<li class="toctree-l1"><a class="reference internal" href="export_DNeuro.html">Export: DNeuro</a></li>
<li class="toctree-l1"><a class="reference internal" href="export_legacy.html">Export: other / legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">INI File Interface:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ini_intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="ini_databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="ini_data_analysis.html">Stimuli data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="ini_environment.html">Stimuli provider (Environment)</a></li>
<li class="toctree-l1"><a class="reference internal" href="ini_layers.html">Network Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="ini_target.html">Targets (outputs &amp; losses)</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="containers.html">Containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="cells.html">Cells</a></li>
<li class="toctree-l1"><a class="reference internal" href="databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="stimuliprovider.html">StimuliProvider</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepnet.html">DeepNet</a></li>
</ul>
<p class="caption"><span class="caption-text">C++ API / Developer:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dev_intro.html">Introduction</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">N2D2</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Performance evaluation tools</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/perfs_tools.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="performance-evaluation-tools">
<h1>Performance evaluation tools<a class="headerlink" href="#performance-evaluation-tools" title="Permalink to this headline">¶</a></h1>
<div class="section" id="key-performance-metrics">
<h2>Key performance metrics<a class="headerlink" href="#key-performance-metrics" title="Permalink to this headline">¶</a></h2>
<p>The key performance metrics are the recall and precision for each class and
the average recall and precision over all the classes. These performance
metrics are automatically computed by the interactive confusion matrix tool
embedded in N2D2, as shown below.</p>
<div class="figure align-default" id="id1">
<img alt="Recall and precision for each class and average recall and precision over all the classes in the interactive confusion matrix tool." src="_images/recall_precision.png" />
<p class="caption"><span class="caption-text">Recall and precision for each class and average recall and precision
over all the classes in the interactive confusion matrix tool.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>The accuracy, in classification context, is not a valid metric for unbalanced
classes, which is typically the case for object detection / segmentation
applications, where the background represent a much larger portion of the
objects or defects. Indeed, in this case, the number of true negative is
easily much larger than the number of true positives, false positives and
false negatives combined, leading to accuracies close to 100% even for no
informative (non working) classification, as illustrated in the figure below.</p>
<div class="figure align-default" id="id2">
<img alt="Recall, Precision and Accuracy definitions." src="_images/recall_definitions.png" />
<p class="caption"><span class="caption-text">Recall, Precision and Accuracy definitions.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<p>During the learning, N2D2 also provides a range of metrics with the
confusion matrix, which are saved in the
<code class="docutils literal notranslate"><span class="pre">*.Target/ConfusionMatrix_*_score.png</span></code> file, as shown in the extract in
the following figure. The metric used for the validation can be specified with
the <code class="docutils literal notranslate"><span class="pre">-valid-metric</span></code> N2D2 command line argument. The default metric used
is the recall (a.k.a. sensitivity).</p>
<div class="figure align-default" id="id3">
<img alt="Metrics associated to the confusion matrix in N2D2." src="_images/metrics.png" />
<p class="caption"><span class="caption-text">Metrics associated to the confusion matrix in N2D2.</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<p>The metric figure used for the validation and the computing of the overall
score in N2D2 is a raw figure, aggregating all the classes and images. It
can therefore differ from the average metric reported in the confusion matrix,
which is the average of the metric of each class.</p>
</div>
<div class="section" id="interactive-confusion-matrix-tool">
<h2>Interactive Confusion Matrix Tool<a class="headerlink" href="#interactive-confusion-matrix-tool" title="Permalink to this headline">¶</a></h2>
<p><strong>N2D2-IP only: available upon request.</strong></p>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>The interactive confusion matrix (main window show in next figure) tool allows
you to explore, sort, combine or extract scores from large confusion matrix.
Its main features are:</p>
<ul class="simple">
<li><p>Sorting;</p></li>
<li><p>Transpose switch;</p></li>
<li><p>Recall and precision;</p></li>
<li><p>Aggregated recall and precision on selected classes;</p></li>
<li><p>Percentages / total count switch;</p></li>
<li><p>Reordering / ordering reset;</p></li>
<li><p>∅ for ignored area.</p></li>
</ul>
<p>The tool can be run after a learning or a test in N2D2, by launching the
<code class="docutils literal notranslate"><span class="pre">*.Target/ConfusionMatrix_*.py</span></code> Python script (requires Python 3.7).</p>
<div class="figure align-default" id="id4">
<img alt="Interactive confusion matrix tool main window." src="_images/interactive_confusion_main.png" />
<p class="caption"><span class="caption-text">Interactive confusion matrix tool main window.</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="single-class-performances-evaluation">
<h3>Single class performances evaluation<a class="headerlink" href="#single-class-performances-evaluation" title="Permalink to this headline">¶</a></h3>
<p>Single class recall and precision score metrics are shown for each row of the
confusion matrix. There are two sets of metrics:</p>
<ul class="simple">
<li><p>Recall w/o Ø and precision w/o Ø: metrics considering only the defect type confusion over the pixels annotated as defect, as show in the table below;</p></li>
</ul>
<blockquote>
<div><div class="figure align-default">
<img alt="_images/recall_precision_table_wo.png" src="_images/recall_precision_table_wo.png" />
</div>
</div></blockquote>
<ul class="simple">
<li><p>Recall and precision: metrics including the defect/no defect confusion as well as the type confusion, as shown in the table below.</p></li>
</ul>
<blockquote>
<div><div class="figure align-default">
<img alt="_images/recall_precision_table.png" src="_images/recall_precision_table.png" />
</div>
</div></blockquote>
</div>
<div class="section" id="classes-aggregation">
<h3>Classes aggregation<a class="headerlink" href="#classes-aggregation" title="Permalink to this headline">¶</a></h3>
<p>When selecting multiple row in the confusion table, the overall recall and
precision are automatically computed for the selection by aggregating the
selected values. They are displayed in the right table, as shown below.</p>
<div class="figure align-default" id="id5">
<img alt="Classes aggregation recall and precision." src="_images/classes_aggregation.png" />
<p class="caption"><span class="caption-text">Classes aggregation recall and precision.</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="selected-items-table-view">
<h3>Selected items table view<a class="headerlink" href="#selected-items-table-view" title="Permalink to this headline">¶</a></h3>
<p>When double-clicking on a single cell in the confusion table, or pressing
the Enter key with a selection, the list of all the images with the
confusions for the selected cells is displayed. The recall and precision are
computed for each (image + target class) pair, as shown below.</p>
<div class="figure align-default" id="id6">
<img alt="List of confusion for selected cells in the confusion matrix." src="_images/confusion_list.png" />
<p class="caption"><span class="caption-text">List of confusion for selected cells in the confusion matrix.</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="items-viewer">
<h3>Items viewer<a class="headerlink" href="#items-viewer" title="Permalink to this headline">¶</a></h3>
<p>When double-clicking on a row in the selected items table view, the ScoreTune
viewer is opened for the corresponding image, showing the estimated classes
in the image, as shown below. The F1 key allows to switch between the
estimated classes and the annotations in the ScoreTune viewer.</p>
<div class="figure align-default" id="id7">
<img alt="Items viewer (using ScoreTune)." src="_images/items_viewer.png" />
<p class="caption"><span class="caption-text">Items viewer (using ScoreTune).</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<p>Automatic Performances Report Generation
It is possible to copy selections from the confusion matrix table or the selected items table using the CTRL + c keyboard shortcut. Selections can be pasted to Microsoft Word or LibreOffice Writer keeping the tabular formatting from the interactive viewer. When copying rows from the selected items table, the corresponding images with the target and estimated annotation are copied as well for each row.</p>
<p>In addition to the copy and paste feature, full report can be generated automatically from the confusion matrix, using the F1 key in the main window. Parameters for the report generation can be modified directly in the Python script and are described below:</p>
</div>
</div>
<div class="section" id="automatic-performances-report-generation">
<h2>Automatic Performances Report Generation<a class="headerlink" href="#automatic-performances-report-generation" title="Permalink to this headline">¶</a></h2>
<p><strong>N2D2-IP only: available upon request.</strong></p>
<p>It is possible to copy selections from the confusion matrix table or the
selected items table using the CTRL + c keyboard shortcut. Selections can be
pasted to Microsoft Word or LibreOffice Writer keeping the tabular formatting
from the interactive viewer. When copying rows from the selected items table,
the corresponding images with the target and estimated annotation are copied
as well for each row.</p>
<p>In addition to the copy and paste feature, full report can be generated
automatically from the confusion matrix, using the F1 key in the main window.
Parameters for the report generation can be modified directly in the Python
script and are described below:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 11%" />
<col style="width: 73%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>Default value</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>nbMainHits</p></td>
<td><p>3</p></td>
<td><p>Maximum number of items to include for the main hits</p></td>
</tr>
<tr class="row-odd"><td><p>thresMainHits</p></td>
<td><p>1000.0</p></td>
<td><p>Threshold in count/slice for matching target and estimated items to consider a main hit</p></td>
</tr>
<tr class="row-even"><td><p>nbMainConfusions</p></td>
<td><p>10</p></td>
<td><p>Maximum number of items to include for the main confusions</p></td>
</tr>
<tr class="row-odd"><td><p>thresMainConfusions</p></td>
<td><p>100.0</p></td>
<td><p>Threshold in count/slice for mismatching target and estimated items to consider a main confusion</p></td>
</tr>
<tr class="row-even"><td><p>nbMainMisses</p></td>
<td><p>10</p></td>
<td><p>Maximum number of items to include for the main misses</p></td>
</tr>
<tr class="row-odd"><td><p>thresMainMisses</p></td>
<td><p>1000.0</p></td>
<td><p>Threshold in count/slice for mismatching target and Ø items to consider a main miss</p></td>
</tr>
</tbody>
</table>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tuto.html" class="btn btn-neutral float-right" title="Tutorials" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="simus.html" class="btn btn-neutral float-left" title="Performing simulations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2019, CEA LIST

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>