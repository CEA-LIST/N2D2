
; ./n2d2.sh "LeNet_SAT.ini" -learn 6000000 -log 100000
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; Naive Model for LeNet topology on MNIST dataset with the 
; SAT methodology
; Step-1: Clamp the weights by runing a learning phase with
; QuantMode=0 ==> Save the fine-tuned weights in a separated folder "weights_clamped"
; Step-2: Starting from previous learned "weights_clamped" parameters
; run a learning phase with QuantMode=1, WeightsRange=255 a,d
; ActivationsRange = 255
; Step-3: Starting from previous learned "weights_clamped" parameters
; run a learning phase with QuantMode=1, WeightsRange=15 and
; ActivationsRange = 15
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;;;;;;;;;;; Step-1 Clamp Experimental Results ;;;;;;;;;;;;;;;;;;;; 
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;Final recognition rate: 98.79%    (error rate: 1.21%)
;    Sensitivity: 98.78% / Specificity: 99.87% / Precision: 98.79%
;    Accuracy: 99.76% / F1-score: 98.78% / Informedness: 98.64%
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;;;;;;;;;;;;;;;;; Step-2 8bits Experimental Results ;;;;;;;;;;;;;; 
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;Final recognition rate: 98.91%    (error rate: 1.09%)
;    Sensitivity: 98.90% / Specificity: 99.88% / Precision: 98.90%
;    Accuracy: 99.78% / F1-score: 98.90% / Informedness: 98.78%
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;;;;;;;;;;;;;;;;; Step-2 6bits Experimental Results ;;;;;;;;;;;;;; 
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;Final recognition rate: 98.93%    (error rate: 1.07%)
;    Sensitivity: 98.92% / Specificity: 99.88% / Precision: 98.93%
;    Accuracy: 99.79% / F1-score: 98.92% / Informedness: 98.80%
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;;;;;;;;;;;;;;;;; Step-3 4bits Experimental Results ;;;;;;;;;;;;;; 
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;Final recognition rate: 98.73%    (error rate: 1.27%)
;    Sensitivity: 98.71% / Specificity: 99.86% / Precision: 98.72%
;    Accuracy: 99.75% / F1-score: 98.71% / Informedness: 98.57%
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;


DefaultModel=Frame_CUDA
$BATCH_SIZE=256
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;SAT Quantization Parameters
$QuantMode=1
$ScaleModeConv=0
$ScaleModeFc=1
$WeightsRange=1;->15 for 4-bits range (2^4 - 1)
$ActivationsRange=255;->15 for 4-bits range (2^4 - 1)
;Final Classifier Range must be at least 255
$FinalClassifierRange=255
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;Global Solver Parameters
$LR=0.05
$WD=0.0
$MOMENTUM=0.0
$Policy=None
$SolverType=SGD
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

; Database
[database]
Type=MNIST_IDX_Database
RandomPartitioning=1

; Environment
[env]
SizeX=32
SizeY=32
BatchSize=${BATCH_SIZE}

[env.Transformation_0]
Type=RescaleTransformation
Width=32
Height=32

[env.Transformation_1]
Type=RangeAffineTransformation
FirstOperator=Divides
FirstValue=255.0

[Conv_def]
Type=Conv
DataType=Float32
ActivationFunction=Linear
WeightsFiller=XavierFiller
WeightsFiller.VarianceNorm=FanOut
WeightsFiller.Scaling=1.0
QWeight=SAT
QWeight.ApplyScaling=${ScaleModeConv}
QWeight.ApplyQuantization=${QuantMode}
QWeight.Range=${WeightsRange}
ConfigSection=common.config


[Fc_def]
Type=Fc
ActivationFunction=Linear
WeightsFiller=NormalFiller
WeightsFiller.Mean=0.0
WeightsFiller.StdDev=0.01
BiasFiller=ConstantFiller
BiasFiller.Value=0.0
QWeight=SAT
QWeight.ApplyScaling=${ScaleModeFc}
QWeight.ApplyQuantization=${QuantMode}
QWeight.Range=${WeightsRange}
ConfigSection=common.config

[Bn_def]
Type=BatchNorm
DataType=Float32
QAct=SAT
QAct.Alpha=6.0
QAct.Range=${ActivationsRange}
QActSolver=${SolverType}
QActSolver.LearningRate=${LR}
QActSolver.LearningRatePolicy=${Policy}
QActSolver.Momentum=${MOMENTUM}
QActSolver.Decay=${WD}
ActivationFunction=Linear
ConfigSection=bn.config

[common.config]
NoBias=1
Solvers.LearningRate=${LR}
Solvers.LearningRatePolicy=${Policy}
Solvers.Momentum=${MOMENTUM}
Solvers.Decay=${WD}

[bn.config]
Solvers.LearningRate=${LR}
Solvers.LearningRatePolicy=${Policy}
Solvers.Momentum=${MOMENTUM}
Solvers.Decay=${WD}


[conv1] Conv_def
Input=env
KernelWidth=5
KernelHeight=5
NbOutputs=6
QWeight.Range=255 ;first conv layer is in 8 bits

[bn1] Bn_def
Input=conv1
NbOutputs=[conv1]NbOutputs

; Non-overlapping max pooling P2
[pool1]
Input=bn1
Type=Pool
PoolWidth=2
PoolHeight=2
NbOutputs=6
Stride=2
Pooling=Max
Mapping.Size=1

[conv2] Conv_def
Input=pool1
KernelWidth=5
KernelHeight=5
NbOutputs=16
[bn2] Bn_def
Input=conv2
NbOutputs=[conv2]NbOutputs

[pool2]
Input=bn2
Type=Pool
PoolWidth=2
PoolHeight=2
NbOutputs=16
Stride=2
Pooling=Max
Mapping.Size=1

[conv3] Conv_def
Input=pool2
KernelWidth=5
KernelHeight=5
NbOutputs=120

[bn3]Bn_def
Input=conv3
NbOutputs=[conv3]NbOutputs

[conv3.drop]
Input=bn3
Type=Dropout
NbOutputs=[conv3]NbOutputs

[fc1] Fc_def
Input=conv3.drop
NbOutputs=84
QAct=SAT
QAct.Alpha=6.0
QAct.Range=${ActivationsRange}
QActSolver=${SolverType}
QActSolver.LearningRate=${LR}
QActSolver.LearningRatePolicy=${Policy}
QActSolver.Momentum=${MOMENTUM}
QActSolver.Decay=${WD}

[fc1.drop]
Input=fc1
Type=Dropout
NbOutputs=[fc1]NbOutputs

[fc2] Fc_def
Input=fc1.drop
ActivationFunction=Linear
NbOutputs=10
QWeight.Range=255 ; last fc layer is in 8 bits

[fc2.Target]


